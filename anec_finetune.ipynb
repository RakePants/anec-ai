{"cells":[{"cell_type":"markdown","metadata":{"id":"BO7MEGbb6mtB"},"source":["# Finetune RuGPTs in huggingface\n","How to finetune RuGPTs models with huggingface. Example for RuGPT3Small. Nfor other models it will take more GPU memory.\n","\n","This notebook is valid for all RuGPTs models except RuGPT3XL.\n","## Install env"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xyhc5yrzR75j","executionInfo":{"status":"ok","timestamp":1678375598931,"user_tz":-300,"elapsed":43288,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"0c442aab-61f5-493b-a8b6-082bf6be9c86","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/transformers\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (3.9.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.2/199.2 KB 9.2 MB/s eta 0:00:00\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.6/7.6 MB 95.7 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.0.dev0) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.0.dev0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.0.dev0) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.0.dev0) (4.0.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml): started\n","  Building wheel for transformers (pyproject.toml): finished with status 'done'\n","  Created wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6703096 sha256=46698e35bd7517390327fa1324428f35635b25a2605080304c91cdebd5c5dca3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ad301m22/wheels/1c/6e/db/b90d9f8554f165a9beb90b593fde94e9e60919270aed78efa0\n","Successfully built transformers\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.1 tokenizers-0.13.2 transformers-4.27.0.dev0\n"]},{"output_type":"stream","name":"stderr","text":["Cloning into 'transformers'...\n"]}],"source":["%%bash\n","git clone https://github.com/huggingface/transformers\n","cd transformers\n","pip install ."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cRTiRkjlFAP9","executionInfo":{"status":"ok","timestamp":1678375642640,"user_tz":-300,"elapsed":43713,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"b2ab856c-86d0-4145-d43f-504b968f35f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Os4vOL5LTOmk","executionInfo":{"status":"ok","timestamp":1678375659371,"user_tz":-300,"elapsed":16737,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"ad4560eb-155c-46b8-aac1-ff981c70b8a0","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.25.1)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n","  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, charset-normalizer, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1P6WSIeTdV5","executionInfo":{"status":"ok","timestamp":1678375665285,"user_tz":-300,"elapsed":5918,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"705b9417-ad46-492b-d9a3-0c8379265390","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting evaluate\n","  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.3.5)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.3.0)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.10.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.13.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.25.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (3.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n","Installing collected packages: evaluate\n","Successfully installed evaluate-0.4.0\n"]}],"source":["!pip install evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJZtWu8u6nwL"},"outputs":[],"source":["!mkdir models/"]},{"cell_type":"markdown","metadata":{"id":"WqwZiumW8WbZ"},"source":["## Download files"]},{"cell_type":"markdown","metadata":{"id":"zoyX62qN_38l"},"source":["## Train \n","The following code download our model and tokenizer from huggingface and finetune model for generating essays.\n","\n","This took aroung ten minutes and obtain perplexity = 13-16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SD6jS49-TAbM","executionInfo":{"status":"ok","timestamp":1678375665673,"user_tz":-300,"elapsed":391,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"701991e3-9155-4798-c4d9-69a901045a6d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-09 15:27:45--  https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/language-modeling/run_clm.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27053 (26K) [text/plain]\n","Saving to: ‘run_clm.py’\n","\n","\rrun_clm.py            0%[                    ]       0  --.-KB/s               \rrun_clm.py          100%[===================>]  26.42K  --.-KB/s    in 0.001s  \n","\n","2023-03-09 15:27:45 (17.8 MB/s) - ‘run_clm.py’ saved [27053/27053]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/language-modeling/run_clm.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCIERP8AS1Dl","executionInfo":{"status":"ok","timestamp":1678378858975,"user_tz":-300,"elapsed":3193304,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"872286cc-ca4c-4e31-a456-d97ea57aee99","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-09 15:27:50.465496: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-09 15:27:52.484972: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-09 15:27:52.485097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-09 15:27:52.485120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","03/09/2023 15:27:57 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","03/09/2023 15:27:57 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=models/anec_model/runs/Mar09_15-27-57_fee438b9134c,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_hf,\n","optim_args=None,\n","output_dir=models/anec_model,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=1,\n","per_device_train_batch_size=1,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=models/anec_model,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","03/09/2023 15:27:57 - INFO - datasets.builder - Using custom data configuration default-cdd67d98585b42b5\n","03/09/2023 15:27:57 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.9/dist-packages/datasets/packaged_modules/text\n","03/09/2023 15:27:58 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-cdd67d98585b42b5/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n","Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-cdd67d98585b42b5/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n","Downloading data files: 100% 2/2 [00:00<00:00, 3256.45it/s]\n","03/09/2023 15:27:58 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","03/09/2023 15:27:58 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Extracting data files: 100% 2/2 [00:02<00:00,  1.03s/it]\n","03/09/2023 15:28:00 - INFO - datasets.builder - Generating train split\n","03/09/2023 15:28:01 - INFO - datasets.builder - Generating validation split\n","03/09/2023 15:28:01 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-cdd67d98585b42b5/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n","100% 2/2 [00:00<00:00, 335.61it/s]\n","Downloading (…)lve/main/config.json: 100% 608/608 [00:00<00:00, 49.3kB/s]\n","[INFO|configuration_utils.py:668] 2023-03-09 15:28:02,190 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\n","[INFO|configuration_utils.py:720] 2023-03-09 15:28:02,208 >> Model config GPT2Config {\n","  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 2048,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.27.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","[INFO|tokenization_auto.py:478] 2023-03-09 15:28:02,513 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:668] 2023-03-09 15:28:02,811 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\n","[INFO|configuration_utils.py:720] 2023-03-09 15:28:02,812 >> Model config GPT2Config {\n","  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 2048,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.27.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Downloading (…)olve/main/vocab.json: 100% 1.71M/1.71M [00:00<00:00, 4.55MB/s]\n","Downloading (…)olve/main/merges.txt: 100% 1.27M/1.27M [00:00<00:00, 4.05MB/s]\n","[INFO|tokenization_utils_base.py:1802] 2023-03-09 15:28:06,064 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/vocab.json\n","[INFO|tokenization_utils_base.py:1802] 2023-03-09 15:28:06,064 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/merges.txt\n","[INFO|tokenization_utils_base.py:1802] 2023-03-09 15:28:06,064 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:1802] 2023-03-09 15:28:06,064 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1802] 2023-03-09 15:28:06,064 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1802] 2023-03-09 15:28:06,064 >> loading file tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:668] 2023-03-09 15:28:06,064 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\n","[INFO|configuration_utils.py:720] 2023-03-09 15:28:06,066 >> Model config GPT2Config {\n","  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 2048,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.27.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","[INFO|configuration_utils.py:668] 2023-03-09 15:28:06,172 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/config.json\n","[INFO|configuration_utils.py:720] 2023-03-09 15:28:06,173 >> Model config GPT2Config {\n","  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 2048,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 2048,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.27.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","[WARNING|logging.py:280] 2023-03-09 15:28:06,273 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Downloading pytorch_model.bin: 100% 551M/551M [00:02<00:00, 207MB/s]\n","[INFO|modeling_utils.py:2398] 2023-03-09 15:28:09,273 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--sberbank-ai--rugpt3small_based_on_gpt2/snapshots/f2f7c585b05a16726efe8974586e10b4d5939082/pytorch_model.bin\n","[INFO|configuration_utils.py:575] 2023-03-09 15:28:09,679 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256,\n","  \"transformers_version\": \"4.27.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:3019] 2023-03-09 15:28:11,472 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","[INFO|modeling_utils.py:3027] 2023-03-09 15:28:11,472 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at sberbank-ai/rugpt3small_based_on_gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","[INFO|modeling_utils.py:2677] 2023-03-09 15:28:11,748 >> Generation config file not found, using a generation config created from the model config.\n","Running tokenizer on dataset:   0% 0/70214 [00:00<?, ? examples/s]03/09/2023 15:28:11 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-cdd67d98585b42b5/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-e235ff3ff0932f14.arrow\n","Running tokenizer on dataset:   0% 0/17507 [00:00<?, ? examples/s]03/09/2023 15:28:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-cdd67d98585b42b5/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-96f060f9a3a64124.arrow\n","Grouping texts in chunks of 2048:   0% 0/70214 [00:00<?, ? examples/s]03/09/2023 15:28:22 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-cdd67d98585b42b5/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2d09d7be53408bb2.arrow\n","Grouping texts in chunks of 2048:   0% 0/17507 [00:00<?, ? examples/s]03/09/2023 15:28:27 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-cdd67d98585b42b5/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-2b58eb07bc62234e.arrow\n","Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 3.81MB/s]\n","/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","[INFO|trainer.py:1738] 2023-03-09 15:28:35,821 >> ***** Running training *****\n","[INFO|trainer.py:1739] 2023-03-09 15:28:35,821 >>   Num examples = 1137\n","[INFO|trainer.py:1740] 2023-03-09 15:28:35,821 >>   Num Epochs = 3\n","[INFO|trainer.py:1741] 2023-03-09 15:28:35,821 >>   Instantaneous batch size per device = 1\n","[INFO|trainer.py:1742] 2023-03-09 15:28:35,821 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n","[INFO|trainer.py:1743] 2023-03-09 15:28:35,821 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1744] 2023-03-09 15:28:35,821 >>   Total optimization steps = 3411\n","[INFO|trainer.py:1745] 2023-03-09 15:28:35,822 >>   Number of trainable parameters = 125231616\n","{'loss': 2.9234, 'learning_rate': 4.267077103488713e-05, 'epoch': 0.44}\n"," 15% 500/3411 [07:22<42:48,  1.13it/s][INFO|trainer.py:2810] 2023-03-09 15:35:58,237 >> Saving model checkpoint to models/anec_model/checkpoint-500\n","[INFO|configuration_utils.py:457] 2023-03-09 15:35:58,239 >> Configuration saved in models/anec_model/checkpoint-500/config.json\n","[INFO|configuration_utils.py:362] 2023-03-09 15:35:58,240 >> Configuration saved in models/anec_model/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:1762] 2023-03-09 15:36:00,183 >> Model weights saved in models/anec_model/checkpoint-500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2163] 2023-03-09 15:36:00,184 >> tokenizer config file saved in models/anec_model/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2170] 2023-03-09 15:36:00,184 >> Special tokens file saved in models/anec_model/checkpoint-500/special_tokens_map.json\n","{'loss': 2.8511, 'learning_rate': 3.5341542069774266e-05, 'epoch': 0.88}\n"," 29% 1000/3411 [14:49<35:31,  1.13it/s][INFO|trainer.py:2810] 2023-03-09 15:43:25,818 >> Saving model checkpoint to models/anec_model/checkpoint-1000\n","[INFO|configuration_utils.py:457] 2023-03-09 15:43:25,819 >> Configuration saved in models/anec_model/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:362] 2023-03-09 15:43:25,821 >> Configuration saved in models/anec_model/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:1762] 2023-03-09 15:43:27,744 >> Model weights saved in models/anec_model/checkpoint-1000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2163] 2023-03-09 15:43:27,745 >> tokenizer config file saved in models/anec_model/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2170] 2023-03-09 15:43:27,745 >> Special tokens file saved in models/anec_model/checkpoint-1000/special_tokens_map.json\n","{'loss': 2.6907, 'learning_rate': 2.801231310466139e-05, 'epoch': 1.32}\n"," 44% 1500/3411 [22:17<28:11,  1.13it/s][INFO|trainer.py:2810] 2023-03-09 15:50:53,699 >> Saving model checkpoint to models/anec_model/checkpoint-1500\n","[INFO|configuration_utils.py:457] 2023-03-09 15:50:53,700 >> Configuration saved in models/anec_model/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:362] 2023-03-09 15:50:53,701 >> Configuration saved in models/anec_model/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:1762] 2023-03-09 15:50:55,512 >> Model weights saved in models/anec_model/checkpoint-1500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2163] 2023-03-09 15:50:55,513 >> tokenizer config file saved in models/anec_model/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2170] 2023-03-09 15:50:55,513 >> Special tokens file saved in models/anec_model/checkpoint-1500/special_tokens_map.json\n","{'loss': 2.6456, 'learning_rate': 2.068308413954852e-05, 'epoch': 1.76}\n"," 59% 2000/3411 [29:45<20:45,  1.13it/s][INFO|trainer.py:2810] 2023-03-09 15:58:21,130 >> Saving model checkpoint to models/anec_model/checkpoint-2000\n","[INFO|configuration_utils.py:457] 2023-03-09 15:58:21,131 >> Configuration saved in models/anec_model/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:362] 2023-03-09 15:58:21,132 >> Configuration saved in models/anec_model/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:1762] 2023-03-09 15:58:22,944 >> Model weights saved in models/anec_model/checkpoint-2000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2163] 2023-03-09 15:58:22,945 >> tokenizer config file saved in models/anec_model/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2170] 2023-03-09 15:58:22,945 >> Special tokens file saved in models/anec_model/checkpoint-2000/special_tokens_map.json\n","{'loss': 2.5724, 'learning_rate': 1.335385517443565e-05, 'epoch': 2.2}\n"," 73% 2500/3411 [37:13<13:24,  1.13it/s][INFO|trainer.py:2810] 2023-03-09 16:05:48,950 >> Saving model checkpoint to models/anec_model/checkpoint-2500\n","[INFO|configuration_utils.py:457] 2023-03-09 16:05:48,951 >> Configuration saved in models/anec_model/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:362] 2023-03-09 16:05:48,953 >> Configuration saved in models/anec_model/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:1762] 2023-03-09 16:05:50,781 >> Model weights saved in models/anec_model/checkpoint-2500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2163] 2023-03-09 16:05:50,782 >> tokenizer config file saved in models/anec_model/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2170] 2023-03-09 16:05:50,782 >> Special tokens file saved in models/anec_model/checkpoint-2500/special_tokens_map.json\n","{'loss': 2.5099, 'learning_rate': 6.02462620932278e-06, 'epoch': 2.64}\n"," 88% 3000/3411 [44:40<06:04,  1.13it/s][INFO|trainer.py:2810] 2023-03-09 16:13:16,768 >> Saving model checkpoint to models/anec_model/checkpoint-3000\n","[INFO|configuration_utils.py:457] 2023-03-09 16:13:16,769 >> Configuration saved in models/anec_model/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:362] 2023-03-09 16:13:16,770 >> Configuration saved in models/anec_model/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:1762] 2023-03-09 16:13:18,566 >> Model weights saved in models/anec_model/checkpoint-3000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2163] 2023-03-09 16:13:18,567 >> tokenizer config file saved in models/anec_model/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2170] 2023-03-09 16:13:18,567 >> Special tokens file saved in models/anec_model/checkpoint-3000/special_tokens_map.json\n","100% 3411/3411 [50:50<00:00,  1.13it/s][INFO|trainer.py:2008] 2023-03-09 16:19:25,887 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 3050.0828, 'train_samples_per_second': 1.118, 'train_steps_per_second': 1.118, 'train_loss': 2.6766467288734974, 'epoch': 3.0}\n","100% 3411/3411 [50:50<00:00,  1.12it/s]\n","[INFO|trainer.py:2810] 2023-03-09 16:19:25,908 >> Saving model checkpoint to models/anec_model\n","[INFO|configuration_utils.py:457] 2023-03-09 16:19:25,909 >> Configuration saved in models/anec_model/config.json\n","[INFO|configuration_utils.py:362] 2023-03-09 16:19:25,911 >> Configuration saved in models/anec_model/generation_config.json\n","[INFO|modeling_utils.py:1762] 2023-03-09 16:19:27,827 >> Model weights saved in models/anec_model/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2163] 2023-03-09 16:19:27,828 >> tokenizer config file saved in models/anec_model/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2170] 2023-03-09 16:19:27,829 >> Special tokens file saved in models/anec_model/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  train_loss               =     2.6766\n","  train_runtime            = 0:50:50.08\n","  train_samples            =       1137\n","  train_samples_per_second =      1.118\n","  train_steps_per_second   =      1.118\n","03/09/2023 16:19:28 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:3064] 2023-03-09 16:19:28,064 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3066] 2023-03-09 16:19:28,064 >>   Num examples = 285\n","[INFO|trainer.py:3069] 2023-03-09 16:19:28,064 >>   Batch size = 1\n","100% 285/285 [01:26<00:00,  3.30it/s]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_accuracy           =     0.5034\n","  eval_loss               =     2.6955\n","  eval_runtime            = 0:01:26.63\n","  eval_samples            =        285\n","  eval_samples_per_second =       3.29\n","  eval_steps_per_second   =       3.29\n","  perplexity              =    14.8134\n","[INFO|modelcard.py:449] 2023-03-09 16:20:55,005 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.5033793570393987}]}\n"]}],"source":["!python run_clm.py \\\n","    --model_name_or_path sberbank-ai/rugpt3small_based_on_gpt2 \\\n","    --train_file drive/MyDrive/anec/train_anec.txt \\\n","    --validation_file drive/MyDrive/anec/valid_anec.txt \\\n","    --per_device_train_batch_size 1 \\\n","    --per_device_eval_batch_size 1 \\\n","    --block_size 2048 \\\n","    --dataset_config_name plain_text \\\n","    --do_train \\\n","    --do_eval \\\n","    --output_dir models/anec_model --overwrite_output_dir"]},{"cell_type":"markdown","metadata":{"id":"QvgntLymArg3"},"source":["## Evaluate model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csHcDJXFDdaW"},"outputs":[],"source":["import numpy as np\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJxPg-cJDhAB","executionInfo":{"status":"ok","timestamp":1678378860961,"user_tz":-300,"elapsed":3,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"017a3e68-106a-430f-90ee-36a0523e6ca2","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f55181763d0>"]},"metadata":{},"execution_count":9}],"source":["np.random.seed(42)\n","torch.manual_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AkUrzKsy_16F"},"outputs":[],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_EMbgO0BTvb"},"outputs":[],"source":["tok = GPT2Tokenizer.from_pretrained(\"models/anec_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fjy0GAuQBYpA"},"outputs":[],"source":["model = GPT2LMHeadModel.from_pretrained(\"models/anec_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irh4H-HDBb6V","executionInfo":{"status":"ok","timestamp":1678378871653,"user_tz":-300,"elapsed":7537,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"7ff01ade-dd84-4807-b118-261290df9168","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50264, 768)\n","    (wpe): Embedding(2048, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",")"]},"metadata":{},"execution_count":13}],"source":["model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQY6A5q7Bd4O"},"outputs":[],"source":["text = \"<s>Полетел Максим в Питер\"\n","inpt = tok.encode(text, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gfJFmeOBj_t","executionInfo":{"status":"ok","timestamp":1678380878146,"user_tz":-300,"elapsed":2651,"user":{"displayName":"Artyom Eryomkin","userId":"01748580897063844258"}},"outputId":"47120812-e502-4e80-d33d-a04801a96f58","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["s>Полетел Максим в Питер. В командировку. А как тебя встретили в Питере? Не очень. Не понравились туалеты и туалеты в гостиных.\n","s>Полетел Максим в Питер! Он же из Москвы! Да, но он там работает и с нами.\n","s>Полетел Максим в Питер и там встретил Настю. Так это же Максим! Так он же в Питере! Да... И там он с Ленкой... Да... Но я же в Питере!\n","s>Полетел Максим в Питер, на Новый год к бабушке. Ну и как? Все хорошо! А вот дедушка в деревне...\n","s>Полетел Максим в Питер. Как? А где он? У жены. Ну и что, что - жена не поехала! Так, так! Самолет улетел в Москву!\n","s>Полетел Максим в Питер, там ему сказали, что там плохо, помогите, там очень плохо!!! Хорошо, тогда передайте, что я ему нужен. Но он не смог меня принять и умер!\n","s>Полетел Максим в Питер, а там... А где его родина? Не знаю. А что ты хочешь? Я хочу, чтобы ты была у меня!\n","s>Полетел Максим в Питер! Врешь! Это было так романтично.\n","s>Полетел Максим в Питер на своем \"Мерседесе\". Я не знаю, куда он полетел...\n","s>Полетел Максим в Питер. Что, так и улетел?\n"]}],"source":["out = model.generate(inpt.cuda(), \n","                     max_length=80, \n","                     repetition_penalty=1.0, \n","                     do_sample=True, \n","                     top_k=20, \n","                     top_p=0.92,\n","                     num_return_sequences=10,\n","                     temperature=1)\n","\n","anec_list = [tok.decode(example) for example in out]\n","\n","for i in anec_list:\n","    print(i.split('<')[1])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/ai-forever/ru-gpts/blob/master/examples/RuGPT3FinetuneHF.ipynb","timestamp":1678293147843}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}